{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, time\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CONFIG_BY_KEY\n",
    "from data_loader import DataLoader\n",
    "from data_loader import DataHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FILE = \"./output/{}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIO(train_index, test_index):\n",
    "\n",
    "    # Prepare data\n",
    "    train_input, train_output = data.getSplit(train_index)\n",
    "    test_input, test_output = data.getSplit(test_index)\n",
    "\n",
    "    datahelper = DataHelper(train_input, train_output, test_input, test_output, config, data)\n",
    "\n",
    "    train_input = np.empty((len(train_input), 0))\n",
    "    test_input = np.empty((len(test_input), 0))\n",
    "\n",
    "    if config.use_target_text:\n",
    "\n",
    "        if config.use_bert:\n",
    "            train_input = np.concatenate([train_input, datahelper.getTargetBertFeatures(mode='train')], axis=1)\n",
    "            test_input = np.concatenate([test_input, datahelper.getTargetBertFeatures(mode='test')], axis=1)\n",
    "        else:\n",
    "            train_input = np.concatenate([train_input,\n",
    "                                          np.array([datahelper.pool_text(utt)\n",
    "                                                    for utt in datahelper.vectorizeUtterance(mode='train')])], axis=1)\n",
    "            test_input = np.concatenate([test_input,\n",
    "                                         np.array([datahelper.pool_text(utt)\n",
    "                                                   for utt in datahelper.vectorizeUtterance(mode='test')])], axis=1)\n",
    "\n",
    "    if config.use_target_video:\n",
    "        train_input = np.concatenate([train_input, datahelper.getTargetVideoPool(mode='train')], axis=1)\n",
    "        test_input = np.concatenate([test_input, datahelper.getTargetVideoPool(mode='test')], axis=1)\n",
    "\n",
    "    if config.use_target_audio:\n",
    "        train_input = np.concatenate([train_input, datahelper.getTargetAudioPool(mode='train')], axis=1)\n",
    "        test_input = np.concatenate([test_input, datahelper.getTargetAudioPool(mode='test')], axis=1)\n",
    "\n",
    "    if train_input.shape[1] == 0:\n",
    "        print(\"Invalid modalities\")\n",
    "        exit(1)\n",
    "\n",
    "    # Aux input\n",
    "\n",
    "    if config.use_author:\n",
    "        train_input_author = datahelper.getAuthor(mode=\"train\")\n",
    "        test_input_author =  datahelper.getAuthor(mode=\"test\")\n",
    "\n",
    "        train_input = np.concatenate([train_input, train_input_author], axis=1)\n",
    "        test_input = np.concatenate([test_input, test_input_author], axis=1)\n",
    "\n",
    "    if config.use_context:\n",
    "        if config.use_bert:\n",
    "            train_input_context = datahelper.getContextBertFeatures(mode=\"train\")\n",
    "            test_input_context =  datahelper.getContextBertFeatures(mode=\"test\")\n",
    "        else:\n",
    "            train_input_context = datahelper.getContextPool(mode=\"train\")\n",
    "            test_input_context =  datahelper.getContextPool(mode=\"test\")\n",
    "\n",
    "        train_input = np.concatenate([train_input, train_input_context], axis=1)\n",
    "        test_input = np.concatenate([test_input, test_input_context], axis=1)\n",
    "\n",
    "    \n",
    "    train_output = datahelper.oneHotOutput(mode=\"train\", size=config.num_classes)\n",
    "    test_output = datahelper.oneHotOutput(mode=\"test\", size=config.num_classes)\n",
    "\n",
    "    return train_input, train_output, test_input, test_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CONFIG_BY_KEY['tav']\n",
    "data = DataLoader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Present Fold: 1\n",
      "vocab size: 1702\n",
      "Loading glove model\n"
     ]
    }
   ],
   "source": [
    "#print(data.data_input[0])\n",
    "results=[]\n",
    "print('test')\n",
    "train_input, train_output, test_input, test_output = (None, )*4\n",
    "for fold, (train_index, test_index) in enumerate(data.getStratifiedKFold()):\n",
    "    config.fold=fold+1\n",
    "    print(\"Present Fold: {}\".format(config.fold))\n",
    "    \n",
    "    train_input, train_output, test_input, test_output = trainIO(train_index, test_index)\n",
    "\n",
    "    \n",
    "   # print(train_input.shape)\n",
    "   # print(train_output.shape)\n",
    "    \n",
    "   # print(test_input)\n",
    "   # print(test_output)\n",
    "    break\n",
    "    #clf = svm_train(train_input, train_output)\n",
    "    #result_dict, result_str = svm_test(clf, test_input, test_output)\n",
    "\n",
    "    #results.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = train_output[:,0]\n",
    "test_output = test_output[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/mustard/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532608695652174\n",
      "0.4855072463768116\n"
     ]
    }
   ],
   "source": [
    "# model 1:-\n",
    "# Using linear support vector classifier\n",
    "lsvc = LinearSVC()\n",
    "# training the model\n",
    "lsvc.fit(train_input, train_output)\n",
    "# getting the score of train and test data\n",
    "print(lsvc.score(train_input, train_output)) # 56.15 Failed to converge\n",
    "print(lsvc.score(test_input, test_output))   # 53.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6684782608695652\n",
      "0.644927536231884\n"
     ]
    }
   ],
   "source": [
    "# model 2:-\n",
    "# Using Gaussuan Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_input, train_output)\n",
    "print(gnb.score(train_input, train_output))  # 66.84\n",
    "print(gnb.score(test_input, test_output))    # 64.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/mustard/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7608695652173914\n"
     ]
    }
   ],
   "source": [
    "# model 3:-\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_input, train_output)\n",
    "print(lr.score(train_input, train_output))  # 100\n",
    "print(lr.score(test_input, test_output))    # 76.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9891304347826086\n",
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(train_input, train_output)\n",
    "print(rfc.score(train_input, train_output))  # 98.91\n",
    "print(rfc.score(test_input, test_output))    # 69.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(train_input, train_output):\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler() if config.svm_scale else FunctionTransformer(lambda x: x, validate=False),\n",
    "        svm.SVC(C=config.svm_c, gamma='scale', kernel='rbf')\n",
    "    )\n",
    "\n",
    "    return clf.fit(train_input, np.argmax(train_output, axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_test(clf, test_input, test_output):\n",
    "\n",
    "    probas = clf.predict(test_input)\n",
    "    y_pred = probas\n",
    "    y_true = np.argmax(test_output, axis=1)\n",
    "\n",
    "    # To generate random scores\n",
    "    # y_pred = np.random.randint(2, size=len(y_pred))\n",
    "\n",
    "    # To generate majority baseline\n",
    "    # y_pred = [0]*len(y_pred)\n",
    "    \n",
    "    result_string = classification_report(y_true, y_pred, digits=3)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(result_string)\n",
    "    return classification_report(y_true, y_pred, output_dict=True, digits=3), result_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present Fold: 1\n",
      "vocab size: 1702\n",
      "Loading glove model\n",
      "[[54 10]\n",
      " [23 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.701     0.844     0.766        64\n",
      "           1      0.836     0.689     0.756        74\n",
      "\n",
      "    accuracy                          0.761       138\n",
      "   macro avg      0.769     0.766     0.761       138\n",
      "weighted avg      0.774     0.761     0.760       138\n",
      "\n",
      "Present Fold: 2\n",
      "vocab size: 1684\n",
      "Loading glove model\n",
      "[[49 18]\n",
      " [24 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.671     0.731     0.700        67\n",
      "           1      0.723     0.662     0.691        71\n",
      "\n",
      "    accuracy                          0.696       138\n",
      "   macro avg      0.697     0.697     0.696       138\n",
      "weighted avg      0.698     0.696     0.695       138\n",
      "\n",
      "Present Fold: 3\n",
      "vocab size: 1713\n",
      "Loading glove model\n",
      "[[53 22]\n",
      " [19 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.736     0.707     0.721        75\n",
      "           1      0.667     0.698     0.682        63\n",
      "\n",
      "    accuracy                          0.703       138\n",
      "   macro avg      0.701     0.703     0.702       138\n",
      "weighted avg      0.704     0.703     0.703       138\n",
      "\n",
      "Present Fold: 4\n",
      "vocab size: 1727\n",
      "Loading glove model\n",
      "[[42 20]\n",
      " [25 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.627     0.677     0.651        62\n",
      "           1      0.718     0.671     0.694        76\n",
      "\n",
      "    accuracy                          0.674       138\n",
      "   macro avg      0.673     0.674     0.673       138\n",
      "weighted avg      0.677     0.674     0.675       138\n",
      "\n",
      "Present Fold: 5\n",
      "vocab size: 1758\n",
      "Loading glove model\n",
      "[[57 20]\n",
      " [16 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.781     0.740     0.760        77\n",
      "           1      0.692     0.738     0.714        61\n",
      "\n",
      "    accuracy                          0.739       138\n",
      "   macro avg      0.737     0.739     0.737       138\n",
      "weighted avg      0.742     0.739     0.740       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'tav'\n",
    "results=[]\n",
    "for fold, (train_index, test_index) in enumerate(data.getStratifiedKFold()):\n",
    "\n",
    "    # Present fold\n",
    "    config.fold = fold+1\n",
    "    print(\"Present Fold: {}\".format(config.fold))\n",
    "\n",
    "    train_input, train_output, test_input, test_output = trainIO(train_index, test_index)\n",
    "\n",
    "    clf = svm_train(train_input, train_output)\n",
    "    result_dict, result_str = svm_test(clf, test_input, test_output)\n",
    "\n",
    "    results.append(result_dict)\n",
    "\n",
    "# Dumping result to output\n",
    "if not os.path.exists(os.path.dirname(RESULT_FILE)):\n",
    "    os.makedirs(os.path.dirname(RESULT_FILE))\n",
    "with open(RESULT_FILE.format(model_name), 'w') as file:\n",
    "    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
